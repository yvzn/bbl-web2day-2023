<section data-background-image="/langchain.webp" data-background-size="50%"
  data-background-gradient="linear-gradient(to bottom, #010727, #45140F)">
  <h2>Langchain</h2>

  <aside class="notes">
    <ul>
      <li>üí° je commence par un exemple de conf tech</li>
      <li>Librairie Python + JS</li>
      <li>Interagir avec un LLM</li>
      <li>Automatiser les t√¢ches courantes</li>
    </ul>
  </aside>
</section>

<section>
  <h3>LLM</h3>

  <p class="fragment">Mod√®le statistique pour le langage</p>
  <p class="fragment">Grand nombre de param√®tres</p>

  <aside class="notes">
    <ul>
      <li>exemple : Davinci OpenAI ChatGPT</li>
      <li>appel√© via une API</li>
    </ul>
  </aside>
</section>

<section>
  <pre>
    A robot <span class="fragment">must</span> <span class="fragment">obey</span> <span class="fragment">the</span> <span class="fragment">orders</span> <span class="fragment">given</span> <span class="fragment">by</span> <span class="fragment">humans</span> <span class="fragment">except...</span>
  </pre>

  <aside class="notes">
    <ul>
      <li>pr√©dit le mot le plus probable √† partir des mots d√©j√† pr√©sents</li>
      <li>prompt ‚â° s√©quence de mots initiaux</li>
    </ul>
  </aside>
</section>

<section>
  <p>M√©morisation</p>
  <p class="fragment">Gestion du contexte</p>

  <aside class="notes">
    <ul>
      <li>le LLM n'a pas de m√©moire !</li>
      <li>ChatGPT a de la m√©moire ?</li>
      <li>simulation gr√¢ce √† l'utilisation d'un contexte</li>
    </ul>
  </aside>
</section>

<section>
  <pre>
Current conversation:
<span class="fragment">Human: Hi, my name is Andrew
AI: </span><span class="fragment">Hellow Andrew. How can I assist you today ?
Human: </span><span class="fragment">What is 1+1
AI: </span><span class="fragment">2
Human: <span class="fragment">What is my name ?
AI: <span class="fragment">...</span>
</pre>

  <aside class="notes">
    <ul>
      <li>le contexte du prompt est enrichi √† chaque question/r√©ponse</li>
      <li>et permet au LLM de "se souvenir"</li>
    </ul>
  </aside>
</section>

<section>
  <p>Vector store</p>
  <p class="fragment">Ingestion de documents</p>

  <aside class="notes">
    <ul>
      <li>Limite √† la taille du contexte</li>
      <li>Une base de donn√©es sp√©cialis√©e (embeddings)</li>
      <li>Alimenter le contexte √† l'aide du bon document</li>
      <li>Charger et stocker diff√©rents formats</li>
    </ul>
  </aside>
</section>

<section>
  <p>Templatisation</p>
  <p class="fragment">Parsing des r√©ponses</p>
  <p class="fragment">Cha√Ænes</p>
  <p class="fragment">Agents sp√©cialis√©s...</p>

  <aside class="notes">
    <ul>
      <li>r√©utiliser un prompt</li>
      <li>Lanchain ‚äÇ abstraction pour changer de LLM</li>
    </ul>
  </aside>
</section>

<section data-background-image="https://live.staticflickr.com/65535/52952736725_8b34594b30_h.jpg">
  <aside class="notes">
    <ul>
      <li>Maxime Thoonsen</li>
      <li>Acc√©l√©rer la cr√©ation de projets NLP ou g√©n√©ralistes</li>
      <li>Simplifier l'exp√©rimentation</li>
    </ul>
  </aside>
</section>